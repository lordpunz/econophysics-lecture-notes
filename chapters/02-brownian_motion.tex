
\chapter{Brownian Motion}


\section{Historical observations}
The history of Brownian motion dates back to the early observations of the botanist Robert Brown. While observing pollen grains suspended in a liquid, he noted their highly erratic and jagged trajectory. These particles were subsequently named \textit{Brownian} particles.


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{images/brownian_motion_2d.png} 
    \caption{Simulation of a Brownian trajectory in two dimensions.}
\end{figure}

Specifically, Brown made the following qualitative observations:
\begin{enumerate}[label=\roman*)]
    \item The motion never seems to cease.
    \item Different particles always move independently of one another.
    \item The particle's material composition (organic or inorganic) or its mass density do not seem to matter.
    \item The motion becomes faster and more agitated as the fluid's temperature increases or as its viscosity decreases.
    \item The motion exhibits scale invariance (it looks similarly jagged at different magnifications).
    \item The trajectory appears to have no tangent at any point.
\end{enumerate}

The first theoretical characterization of this phenomenon was provided by Albert Einstein in two revolutionary papers published in 1905 \cite{Einstein1905, Einstein1906}. We will now illustrate the key steps of his reasoning.
\section{Einstein's first paper}
\subsection{From random walk to the diffusion equation}
He considered a one-dimensional, infinitely extended fluid composed of an ensemble of particles. The Brownian particle undergoes a series of discrete displacements, or "jumps", over very small, successive time intervals, denoted by $\tau$, much smaller than the observation time $T$.


\begin{center}
\begin{tikzpicture}

  \draw[thick] (-3,0) -- (3,0);

  \filldraw[black] (-1,0) circle (2pt);
  \filldraw[black] (1,0) circle (2pt);

  \draw[dashed] (-1,0) arc (180:0:1cm and 0.5cm);

  \node[above] at (0,0.5) {$\Delta$};
\end{tikzpicture}
\end{center}

To describe the statistics of these jumps, Einstein introduced an auxiliary function, $\phi(\Delta)$, which is the probability density function (PDF) for a jump of magnitude $\Delta$. The term $\phi(\Delta)d\Delta$ represents the probability that a single jump has a magnitude between $\Delta$ and $\Delta+d\Delta$. This function is defined by two fundamental properties based on physical reasoning:
\begin{itemize}
    \item \textbf{Normalization}: The particle must perform a jump of some magnitude, so the total probability over all possible jumps must be equal to 1. This is expressed by the normalization condition:
    \[
    \int_{-\infty}^{\infty} \phi(\Delta) \,d\Delta = 1.
    \]
    \item \textbf{Symmetry}: In the absence of any external force or drift, the fluid is isotropic. Therefore, a jump to the right ($+\Delta$) is as probable as a jump of the same magnitude to the left ($-\Delta$). This implies that the function $\phi$ must be an even function:
    \[
    \phi(\Delta) = \phi(-\Delta).
    \]
\end{itemize}

The main goal, however, is to find $p(x,t)$, which represents the number of particles per unit length at position $x$ and time $t$. If we consider $p(x,t)$ as the probability density for a single particle, it must be normalized such that its integral over all space is 1:
\[
\int_{-\infty}^{\infty} p(x,t) \,dx = 1.
\]
The probability of finding the particle in the infinitesimal interval $[x, x+dx]$ is therefore $p(x,t)dx$.

The core idea is to relate the particle density at time $t_f = t+\tau$ to the density at time $t_i = t$. The density of particles at position $x$ at the future time $t+\tau$, denoted $p(x, t+\tau)$, is the sum of probabilities of particles arriving at $x$ from all possible previous positions. A particle that ends up at $x$ must have been at a position $x+\Delta$ at time $t$ and then performed a jump of size $\Delta$. Summing over all possible jumps $\Delta$:
\[
p(x, t+\tau) = \int_{-\infty}^{\infty} P(x+\Delta, t) \phi(\Delta) \,d\Delta.
\]

Now, we perform a Taylor expansion for small $\tau$ and small $\Delta$. The left side is expanded in time:
\[
p(x, t+\tau) \approx p(x,t) + \tau \frac{\partial p(x,t)}{\partial t} + \dots;
\]
the term $p(x+\Delta, t)$ inside the integral is expanded in space around the position $x$:
\[
p(x+\Delta, t) \approx p(x,t) + \Delta \frac{\partial p(x,t)}{\partial x} + \frac{\Delta^2}{2} \frac{\partial^2 p(x,t)}{\partial x^2} + \dots;
\]
s3ubstituting these expansions back into the main equation:
\[
p(x,t) + \tau \frac{\partial P}{\partial t} \approx \int_{-\infty}^{\infty} \left[ p(x,t) + \Delta \frac{\partial p}{\partial x} + \frac{\Delta^2}{2} \frac{\partial^2 p}{\partial x^2} \right] \phi(\Delta) \,d\Delta.
\]
We can split the integral by linearity:
\[
\tau \frac{\partial p}{\partial t} \approx p(x,t) \underbrace{\int \phi(\Delta)d\Delta}_{=1} + p(x,t) + \frac{\partial p}{\partial x} \underbrace{\int \Delta \phi(\Delta)d\Delta}_{=0} + \frac{1}{2}\frac{\partial^2 p}{\partial x^2} \int \Delta^2 \phi(\Delta)d\Delta.
\]
The terms simplify based on the properties of $\phi$.

So we are left with:
\[
\tau \frac{\partial p(x,t)}{\partial t} \approx \frac{1}{2}\frac{\partial^2 p(x,t)}{\partial x^2} \int_{-\infty}^{\infty} \Delta^2 \phi(\Delta) \,d\Delta.
\]
Dividing by $\tau$, we get:
\[
\frac{\partial p(x,t)}{\partial t} = D \frac{\partial^2 p(x,t)}{\partial x^2}.
\]
This is the \emph{diffusion equation} (with $D=1$ it becomes the well known heat equation), where $D$ is the \emph{diffusion coefficient}, defined as:
\[
D := \frac{1}{2\tau} \int_{-\infty}^{\infty} \Delta^2 \phi(\Delta) \,d\Delta.
\]
Since $\Delta^2 \ge 0$ and $\phi(\Delta) \ge 0$, the integral is positive, thus $D>0$. The dimensions of $D$ are length squared per unit time, $[D] = L^2 T^{-1}$.


\subsection{Solution of the diffusion equation}
We now solve the diffusion equation with a specific initial condition. Physically, it is natural to assume that the process starts with the particle (or all particles) located exactly at the origin at time $t=0$. This condition is represented mathematically by the Dirac delta function, $\delta(x)$. It represents an instantaneous, infinitely concentrated point source. The solution $p(x,t)$ will then describe how this initial certainty "diffuses" into a probability distribution over time.

The problem is thus defined by the partial differential equation and its initial condition:
\begin{align*}
    \frac{\partial p(x,t)}{\partial t} &= D \frac{\partial^2 p(x,t)}{\partial x^2}; \\
    p(x,0) &= \delta(x).
\end{align*}
We solve this using the Fourier transform. Let $p(k,t)$ be the Fourier transform of $p(x,t)$ with respect to the spatial variable $x$. The transform pair is defined as:
\begin{align*}
    \text{Inverse Transform:} \quad p(x,t) &= \int_{-\infty}^{\infty} e^{ikx} p(k,t) \,dk; \\
    \text{Transform:} \quad p(k,t) &= \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{-ikx} p(x,t) \,dx.
\end{align*}
First, we transform the initial condition. Using the integral representation of the Dirac delta, $\delta(x) = \frac{1}{2\pi} \int e^{ikx} dk$,  
\[
p(k,0) = \frac{1}{2\pi}.
\]
Next, we transform the diffusion equation itself. The time derivative remains, while the spatial derivative becomes a multiplication by $(ik)^2 = -k^2$:
\[
\mathcal{F}\left[\frac{\partial p}{\partial t}\right] = D \cdot \mathcal{F}\left[\frac{\partial^2 p}{\partial x^2}\right] \implies \frac{\partial p(k,t)}{\partial t} = D(-k^2)p(k,t).
\]
This transforms the partial differential equation in $(x,t)$ into a simpler ordinary differential equation in the variable $t$ for each value of $k$:
\begin{align*}
    \frac{\partial p(k,t)}{\partial t} &= -Dk^2 p(k,t); \\
    p(k,0) &= \frac{1}{2\pi}.
\end{align*}
This is a first-order linear ODE with constant coefficients, which can be solved by separation of variables.

Let's treat $k$ as a constant parameter and solve the ODE for the function $f(t) = p(k,t)$:
\[
\frac{df(t)}{dt} = (-Dk^2) f(t).
\]
Separating the variables $f$ and $t$:
\[
\frac{df}{f} = -Dk^2 \,dt.
\]
Integrating both sides:
\[
\int \frac{1}{f} \,df = \int -Dk^2 \,dt \implies \ln|f| = -Dk^2 t + C_0.
\]
where $C_0$ is the constant of integration. Exponentiating both sides gives:
\[
f(t) = e^{-Dk^2 t + C_0} = e^{C_0} e^{-Dk^2 t} = C e^{-Dk^2 t}.
\]
We find the constant $C$ using the initial condition $p(k,0) = 1/(2\pi)$:
\[
p(k,0) = C e^{0} = C \implies C = \frac{1}{2\pi}.
\]
Thus, the solution in the Fourier space is:
\[
p(k,t) = \frac{1}{2\pi} e^{-Dk^2 t}.
\]

To find the solution in the original space, we apply the inverse Fourier transform to $p(k,t)$:
\[
p(x,t) = \int_{-\infty}^{\infty} e^{ikx} p(k,t) \,dk = \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{ikx} e^{-Dk^2 t} \,dk = \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{-Dk^2 t + ikx} \,dk.
\]
To solve this Gaussian integral, we complete the square in the exponent:
\begin{align*}
-Dtk^2 + ikx &= -Dt \left( k^2 - \frac{ix}{Dt}k \right) \\
             &= -Dt \left[ \left( k - \frac{ix}{2Dt} \right)^2 - \left( \frac{ix}{2Dt} \right)^2 \right] \\
             &= -Dt \left( k - \frac{ix}{2Dt} \right)^2 - Dt \left( \frac{x^2}{4D^2t^2} \right) \\
             &= -Dt \left( k - \frac{ix}{2Dt} \right)^2 - \frac{x^2}{4Dt}.
\end{align*}
Substituting this back into the integral:
\[
p(x,t) = \frac{1}{2\pi} \int_{-\infty}^{\infty} \exp\left[-Dt\left(k - \frac{ix}{2Dt}\right)^2 - \frac{x^2}{4Dt}\right] \,dk = \frac{1}{2\pi} e^{-\frac{x^2}{4Dt}} \int_{-\infty}^{\infty} e^{-Dt\left(k - \frac{ix}{2Dt}\right)^2} \,dk.
\]
The remaining integral is a standard Gaussian integral of the form $\int e^{-a(u-b)^2}du = \sqrt{\pi/a}$. Here, $a=Dt$. The complex shift $b=ix/(2Dt)$ does not change the result of the integral over the real line.
\[
\int_{-\infty}^{\infty} e^{-Dt\left(k - \frac{ix}{2Dt}\right)^2} \,dk = \sqrt{\frac{\pi}{Dt}}.
\]
Therefore, the solution is:
\[
p(x,t) = \frac{1}{2\pi} e^{-\frac{x^2}{4Dt}} \sqrt{\frac{\pi}{Dt}} = \frac{1}{\sqrt{4\pi Dt}} e^{-\frac{x^2}{4Dt}}.
\]
This is a Gaussian distribution with mean $\mu=0$ and variance $\sigma^2_t = 2Dt$.

A minimal and standard choice for the diffusion coefficient is $D=1/2$. This specific case defines the standard Brownian motion, also known as the \emph{Wiener process}. The probability density function becomes:
\[
p(x,t) = \frac{1}{\sqrt{2\pi t}} e^{-\frac{x^2}{2t}}.
\]
This process is a cornerstone of stochastic calculus. It exhibits scale invariance and is considered the first and most fundamental example of a 1D fractal process.


\subsection{Physical interpretation and statistical consequences}
The solution we found is a  normal distribution:
\[
p(x,t) = \frac{1}{\sqrt{2\pi\sigma_t^2}} e^{-\frac{x^2}{2\sigma_t^2}}.
\]
where the variance $\sigma_t^2$ is time-dependent:
\[
\sigma_t^2 = 2Dt.
\]


We can calculate the key moments of this distribution.
\begin{itemize}
    \item \textbf{Mean Position}: The average position of the particle is given by the expectation value $\langle x \rangle$. Since the Gaussian is centered at zero (it is an even function) and we are integrating over a symmetric domain, the mean is zero.
    \[
    \langle x \rangle = \int_{-\infty}^{\infty} x \, p(x,t) \,dx = 0.
    \]
    This confirms that the diffusion process has no drift; the particle is equally likely to be found on either side of the origin.

    \item \textbf{Variance}: The variance measures the spread of the distribution.
    \begin{align*}
        \text{Var}[x] &= \langle (x - \langle x \rangle)^2 \rangle = \langle x^2 \rangle - \langle x \rangle^2 = \langle x^2 \rangle \\
        &= \int_{-\infty}^{\infty} x^2 \, p(x,t) \,dx = \sigma_t^2 = 2Dt.
    \end{align*}
    This is a very important result of diffusion theory: the variance of the particle's position grows linearly with time. This means the particle spreads out, and our uncertainty about its location increases as time passes. Standard diffusive processes are thus Gaussian.
\end{itemize}

The evolution of the probability density is a macroscopic description of the ensemble of particles, not the path of a single particle. It starts as an infinitely sharp Dirac delta at $t=0$ and then "spreads out" as a Gaussian with increasing width, as illustrated below.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{images/gaussian_evolution.pdf}
    \caption{Evolution of the probability density $p(x,t)$ over time. Starting from a Dirac delta at $t=0$, the distribution spreads out as a Gaussian with variance $\sigma_t^2=2Dt$ increasing linearly in time.}
    \label{fig:gaussian_evolution}
\end{figure}


Another relevant quantity to characterize the displacement of the particle is the Mean Squared Displacement (MSD). It is defined as the average squared distance the particle has traveled from its starting point.
\[
\text{MSD}(t) = \langle [x(t) - x(0)]^2 \rangle.
\]
Let's consider two cases:
\begin{itemize}
    \item If the particle starts at the origin, $x(0)=0$:
    \[
    \text{MSD} = \langle [x(t)]^2 \rangle = \langle x^2(t) \rangle = 2Dt.
    \]
    The MSD is simply the variance.

    \item If the particle starts at a generic position $x(0)=x_0$: 
    \begin{align*}
        \text{MSD} &= \langle [x(t) - x_0]^2 \rangle \\
        &= \langle x^2(t)\rangle + x_0^2 - 2x_0  \langle x(t)\rangle\\
        &= \langle x^2(t)\rangle + x_0^2 - 2x_0^2  \\
        & = x_0^2  + 2Dt - x_0^2 \\
        & = 2Dt.
    \end{align*}
\end{itemize}
In both cases, the MSD grows linearly with time. 

The typical distance traveled by the particle, the mean free path  $\lambda_x$, can be estimated as the root of the MSD.
\[
\lambda_x = \sqrt{\text{MSD}} = \sqrt{2Dt}.
\]
This shows that the characteristic displacement of a diffusing particle grows not with time $t$, but with its square root. This sub-linear growth is a direct consequence of the random, back-and-forth nature of the motion.

\section{Einstein's second paper}

Let us now investigate the physical significance of the diffusion coefficient $D$. We recall from the studies of R. Brown, that the motion of suspended (Brownian) particles becomes more intense as the temperature $T$ rises and as the viscosity $\eta$ of the liquid or the radius $R$ of the particles decrease. Thus, we need to link these macroscopic parameters (the radius of the particle -- $\sim10^{-6}m$ -- is sufficiently large to neglect quantum effects and consider it a macroscopic object) to the diffusion coefficient.\\
Let us consider a statistical ensemble of $N$ identical Brownian particles of radius $R$, suspended in a three-dimensional tank liquid of temperature $T$ and viscosity $\eta$. We consider three main forces acting on each particle in the vertical direction ($x$):
\begin{itemize}
	\item Gravitational pull: $F_G=-mg=-\frac{d}{dx}(V_G(x))$, with $V_G(x)=mgx$.
	\item Archimede's buoyancy: $F_A(x)=\rho(x) g Vol<<F_G$ (negligible).
	\item Stokes drag: $F_S=-6\pi\eta R v $ (valid for low Reynolds' number).
\end{itemize}
Restricting our attention to the stationary regime we can define a drift velocity of $v_d=\frac{F_G}{6\pi \eta R}$ and a superficial current of matter (number of particles that cross the unit of surface in the unit of time) $J_{drift}(x)=v_d\rho(x)$. Under the hypothesis of statistical equilibrium and classical physics, Boltzmann formula entails that $\rho(E)=N\frac{e^{-\beta E}}{\mathcal{Z}}$, with $\beta=(k_BT)^{-1}$ and $E=V(x)+mv^2/2$. Hence, if we have that $\rho(0)=Ne^{-\beta m v^2/2}$ ($\iff V(0)=0$)
\[
	\frac{\rho(x)}{\rho(0)}=e^{-\beta V(x)}.
\]
This is the case of the gravitational potential $V(x)=V_G(x)=mgx$, which recovers the so-called \textit{barometric distribution} $\rho(x)=\rho(0)e^{-\beta F_G x}=\rho(0)e^{-\beta m g x}$.\\
Since the concentration of the Brownian particles increases with the depth of the liquid, each particle, while falling, experiences an increasing upward "force" generated by the consecutive scattering with other Brownian particles. The analytic form of the current generated by this effect is nothing more than Fick's diffusion current $J_{diff}(x)=-D_{E.S.}\frac{d}{dx}\rho(x)$, for some $D_{E.S.}\in \mathbb{R}^+$. Considering the stationary regime, we demand $\rho(x)$ to be constant over time, \textit{i.e.}, with zero net flow $J_{diff}-J_{drift}=0$. Identifying $V(x)=Fx$ for some constant force $F=F_G+F_S$
\begin{align*}
	& -D\frac{d\rho(x)}{dx}-v_d\rho(x)=0 \implies\\
	& e^{-\beta Fx}\frac{F}{6\pi \eta R}=\rho(x)v_d=-D_{E.S.}\frac{d\rho(x)}{dx}=D_{E.S.}\beta F e^{-\beta F x}\implies\\
	& D_{E.S.} =\frac{k_BT}{6\pi\eta R},
\end{align*}
where "E.S." stands for Einstein-Smoluchowski. With this characterisation, we find all the properties of the chaotic motion described by R. Brown with the exception of self-similarity\footnote{See J. B. Perrin's work for an experimental verification of the Einstein-Smoluchowski formula.}.\\
Considering a statistical ensemble, we can identify $p(x,y)\leftrightarrow \rho(x,t)$. Recalling the following formula for Einstein's first work
\begin{align*}
	& \partial_t\rho(x,t)=D\partial_x^2\rho(x,t)\implies\\
	& 0=\partial_t\rho(x,t)-\partial_x\{D\partial_x\rho(x,t)\}=\partial_t\rho(x,t)+\partial_x J(x,t),
\end{align*}
recovering a continuity equation for $J(x,t)=-D\partial_x\rho(x,t)$. In the stationary regime we set $\rho(x,t)\to \rho_S(x)$, entailing that $\partial_t\rho_S=0$ and consequently $\partial_xJ_S=0$. In this setting, we find $J(x)=-D\partial_x\rho_S(x)$. This observation fixes $D=D_{E.S.}$.\\
We now would like to extend Einstein's characterisation of the Brownian motion by describing the trajectory of the Brownian particles. This, for obvious reasons, cannot be done in a deterministic way, but an attempt to delineate an average trajectory was made by Langevin: his reasoning goes as follows.\\
He considered a statistical ensemble of Brownian particles of mass $m$ and radius $R$ suspended in a 1-dimensional fluid of temperature $T$ and viscosity $\eta$ in statistical equilibrium. Langevin admits a non-symmetric "jump" distribution, whose unbalance between the probability of a right and a left jump generates an overall drift velocity $v_d$. The first principle of dynamics can be written as $ma=F=F^{(1)}+F^{(2)}$, with $F^{(1)}=F_S=6\pi\eta Rv$ the deterministic Stokes force while $F^{(2)}=\xi(t)$ which models the stochastic particles scatterings as \textit{White Noise}. We choose $\xi(t)$ such that for any time $t$ the ensemble average reads
\[
	\langle \xi(t)\rangle_{Ensemble}=0, \;\mathrm{for}\,\,\mathrm{any}\; t\in \mathbb{R}.
\]
If we consider $\xi(t)\equiv 0$, we find a deterministic differential equation $m\frac{dv(t)}{dt}=-6\pi\eta R v(t)$, which has for a solution $v(t)=v(0)e^{-t/\tau}$, with $\tau=m/6\pi\eta R$. Considering the full equation instead, we have
\begin{align*}
	&m\frac{d^2x}{dt^2}=-6\pi\eta R\frac{dx}{dt}+\xi(t)\\
	& mx\frac{d^2x}{dt^2}=-6\pi\eta Rx\frac{dx}{dt}+x\xi(t)\\
\end{align*}
using the fact that $\frac{d(x^2)}{dt}=2x\frac{dx}{dt}$ and consequently $\frac{d(x^2)}{dt^2}=2(\frac{dx}{dt})^2+2x\frac{d^2x}{dt}$, we have
\begin{align*}
	&\bigg(\frac{m}{2}\bigg)\bigg(2x\frac{d^2x}{dt^2}\bigg)=\bigg(\frac{m}{2}\bigg)\bigg(\frac{d^2(x^2)}{dt^2}-2v^2\bigg),\\
\end{align*}
then, substituting in the previous equation to express everything in function of $x^2$
\begin{align*}
	&\bigg(\frac{m}{2}\bigg)\frac{d^2(x^2)}{dt^2}-mv^2=-3\pi\eta R\frac{d(x^2)}{dt}+x\xi(t).
\end{align*}
We observe that $x$ is a stochastic variable since it depends on $\xi(t)$. In this spirit we evaluate the ensemble average of the differential equation, \textit{i.e.}
\begin{align*}
	&\bigg(\frac{m}{2}\bigg)\frac{d^2}{dt^2}\langle x^2 \rangle-\langle mv^2\rangle =-3\pi\eta R\frac{d}{dt}\langle x^2\rangle +\langle x\xi(t)\rangle.
\end{align*}
We recall that under the hypothesis statistical equilibrium, it holds the Equipartition Theorem, which entails that $\langle \frac{mv^2}{2}\rangle=\frac{k_BT}{2}$. In addition, since $\xi(t)$ is is independent from the particle's position (\textit{Markov process}), then we can factorise $\langle x\xi(t)\rangle =\langle x\rangle \langle \xi(t)\rangle=0$. Collecting all of the above observations in one formula, gives
\begin{align*}
	\frac{m}{2}\frac{d^2}{dt^2}\langle x^2 \rangle +3\pi\eta R\frac{d}{dt}\langle x^2\rangle =k_BT.
\end{align*}
We observe that, despite in the initial differential equation a stochastic term was added, in the final equation it does not appear: this is because we supposed $\langle \xi(t)\rangle =0$. However, the trace of its existence lies in the fact that to erase the stochastic term, we had to consider an ensamble-average equation, giving up the "determinability" of our result.\\
If we set $f(t)=\frac{d}{dt}\langle x^2\rangle$, we have that 
\begin{align*}
	&f'(t)+af(t)=b, \;a=6\pi\eta R/m, \;b=2k_BT/m\implies\\
	&f(t)=f_0(t)+f_p(t)=Ce^{-at}+b/a\implies\\
	&\frac{d}{dt}\langle x^2\rangle =Ce^{-\frac{6\pi\eta R t}{m}}+\frac{k_BT}{3\pi\eta R}=Ce^{-t/\tau}+\frac{k_BT}{3\pi\eta R},
\end{align*}
with $\tau=m/6\pi\eta R\sim 10^{-8}s$. After the transient state (\textit{i.e.} for $t>>\tau$) $e^{-t/\tau}\approx 0$, as a consequence, if we integrate the above equation on $[0,t]$ we have that
\begin{align*}
	\langle x^2(t)\rangle =\langle x^2(0)\rangle +\frac{k_BT}{3\pi\eta R}t=\langle x^2(0)\rangle +2t D_{E.S.}.
\end{align*}
This result should make the reader "jump on their chair" since explicitly confirms the equivalence of the macroscopic (statistical -- $p(x,t)$) derivation by Einstein-Smoluchowski with the microscopic (pseudo-deterministic -- $\langle x(t)\rangle$) derivation by Langevin. 






















